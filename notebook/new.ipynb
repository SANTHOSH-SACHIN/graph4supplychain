{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error,mean_absolute_percentage_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import SAGEConv, GATConv, GeneralConv, TransformerConv\n",
    "from torch.nn import GRU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_layers, out_channels):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        prev_layer = in_channels\n",
    "\n",
    "        for hidden_dim in hidden_layers:\n",
    "            layers.append(nn.Linear(prev_layer, hidden_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            prev_layer = hidden_dim\n",
    "\n",
    "        layers.append(nn.Linear(prev_layer, out_channels))\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)\n",
    "\n",
    "\n",
    "class GRUDecoder(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, hidden_gru=64):\n",
    "        super().__init__()\n",
    "        hidden_layers = [128, 64, 32]\n",
    "\n",
    "        self.gru = nn.GRU(in_channels, hidden_gru, batch_first=True)\n",
    "        self.mlp = MLP(hidden_gru, hidden_layers, out_channels)\n",
    "\n",
    "    def forward(self, z):\n",
    "        gru_out, _ = self.gru(z)\n",
    "        output = self.mlp(gru_out.squeeze())\n",
    "        return output\n",
    "\n",
    "\n",
    "class GNNEncoder1(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv((-1, -1), hidden_channels)\n",
    "        self.conv2 = SAGEConv((-1, -1), out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index,edge_attr=None):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "class GNNEncoder2(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GATConv((-1, -1), hidden_channels, add_self_loops=False)\n",
    "        self.conv2 = GATConv((-1, -1), out_channels, add_self_loops=False)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        x = self.conv1(x, edge_index, edge_attr).relu()\n",
    "        x = self.conv2(x, edge_index, edge_attr)\n",
    "        return x\n",
    "\n",
    "class GNNEncoder3(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GeneralConv((-1, -1), hidden_channels, in_edge_channels=-1)\n",
    "        self.conv2 = GeneralConv((-1, -1), out_channels, in_edge_channels=-1)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        x = self.conv1(x, edge_index, edge_attr).relu()\n",
    "        x = self.conv2(x, edge_index, edge_attr)\n",
    "        return x\n",
    "\n",
    "class GNNEncoder4(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, heads=1, dropout=0.0, edge_dim=None):\n",
    "        super().__init__()\n",
    "        self.conv1 = TransformerConv(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=hidden_channels,\n",
    "            heads=heads,\n",
    "            concat=True,\n",
    "            beta=False,\n",
    "            dropout=dropout,\n",
    "            edge_dim=edge_dim,\n",
    "            bias=True,\n",
    "            root_weight=True\n",
    "        )\n",
    "        self.conv2 = TransformerConv(\n",
    "            in_channels=hidden_channels * heads,\n",
    "            out_channels=out_channels,\n",
    "            heads=heads,\n",
    "            concat=True,\n",
    "            beta=False,\n",
    "            dropout=dropout,\n",
    "            edge_dim=edge_dim,\n",
    "            bias=True,\n",
    "            root_weight=True\n",
    "        )\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr=None):\n",
    "        x = self.conv1(x, edge_index, edge_attr).relu()\n",
    "        x = self.conv2(x, edge_index, edge_attr)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_channels, out_channels, edge_index, edge_attr=None, encoder_type='GNNEncoder4'):\n",
    "        super().__init__()\n",
    "        if encoder_type == 'GNNEncoder1':\n",
    "            self.encoder = GNNEncoder1(hidden_channels, hidden_channels)\n",
    "        elif encoder_type == 'GNNEncoder2':\n",
    "            self.encoder = GNNEncoder2(hidden_channels, hidden_channels)\n",
    "        elif encoder_type == 'GNNEncoder3':\n",
    "            self.encoder = GNNEncoder3(hidden_channels, hidden_channels)\n",
    "        elif encoder_type == 'GNNEncoder4':\n",
    "            self.encoder = GNNEncoder4(input_size, hidden_channels, hidden_channels, edge_dim=edge_attr.size(1) if edge_attr is not None else None)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown encoder type: {encoder_type}\")\n",
    "\n",
    "        self.decoder = GRUDecoder(hidden_channels, out_channels)\n",
    "        self.edge_index = edge_index\n",
    "        self.edge_attr = edge_attr\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x, self.edge_index, self.edge_attr)\n",
    "        z = z.unsqueeze(1)\n",
    "        return self.decoder(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    speed_data = pd.read_csv('dataset/PeMSD7_V_228.csv', header=None)\n",
    "    adjacency_matrix = pd.read_csv('dataset/PeMSD7_W_228.csv', header=None)\n",
    "except FileNotFoundError:\n",
    "    import os\n",
    "    import requests\n",
    "    import zipfile\n",
    "\n",
    "    url = \"https://github.com/VeritasYin/STGCN_IJCAI-18/raw/master/dataset/PeMSD7_Full.zip\"\n",
    "    os.makedirs('dataset', exist_ok=True)\n",
    "    response = requests.get(url)\n",
    "    zip_path = 'dataset/PeMSD7_Full.zip'\n",
    "    with open(zip_path, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall('dataset')\n",
    "\n",
    "    speed_data = pd.read_csv('dataset/PeMSD7_V_228.csv', header=None)\n",
    "    adjacency_matrix = pd.read_csv('dataset/PeMSD7_W_228.csv', header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "speed_data = scaler.fit_transform(speed_data)\n",
    "\n",
    "train_size = int(len(speed_data) * 0.8)\n",
    "train_data = speed_data[:train_size]\n",
    "test_data = speed_data[train_size:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torch.tensor(train_data, dtype=torch.float32)\n",
    "test_data = torch.tensor(test_data, dtype=torch.float32)\n",
    "\n",
    "# Create edge index from adjacency matrix\n",
    "adjacency_matrix = adjacency_matrix.values  # Convert to numpy array\n",
    "edge_index = torch.tensor(np.stack(np.nonzero(adjacency_matrix)), dtype=torch.long)\n",
    "\n",
    "# Create a graph object\n",
    "graph = Data(edge_index=edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = speed_data.shape[1]\n",
    "hidden_channels = 64\n",
    "out_channels = speed_data.shape[1]\n",
    "num_epochs = 50\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_type = 'GNNEncoder4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(input_size, hidden_channels, out_channels, graph.edge_index, edge_attr=None, encoder_type=encoder_type)\n",
    "optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 1.0056010484695435\n",
      "Epoch 2/50, Loss: 1.0045969486236572\n",
      "Epoch 3/50, Loss: 1.0037012100219727\n",
      "Epoch 4/50, Loss: 1.0027871131896973\n",
      "Epoch 5/50, Loss: 1.0016757249832153\n",
      "Epoch 6/50, Loss: 1.0003234148025513\n",
      "Epoch 7/50, Loss: 0.9986869096755981\n",
      "Epoch 8/50, Loss: 0.9967398643493652\n",
      "Epoch 9/50, Loss: 0.9943762421607971\n",
      "Epoch 10/50, Loss: 0.9914581775665283\n",
      "Epoch 11/50, Loss: 0.9878917336463928\n",
      "Epoch 12/50, Loss: 0.9835392236709595\n",
      "Epoch 13/50, Loss: 0.9783504605293274\n",
      "Epoch 14/50, Loss: 0.9722738862037659\n",
      "Epoch 15/50, Loss: 0.9651872515678406\n",
      "Epoch 16/50, Loss: 0.9570857286453247\n",
      "Epoch 17/50, Loss: 0.9480245113372803\n",
      "Epoch 18/50, Loss: 0.938081681728363\n",
      "Epoch 19/50, Loss: 0.9274635910987854\n",
      "Epoch 20/50, Loss: 0.9163833260536194\n",
      "Epoch 21/50, Loss: 0.9051623344421387\n",
      "Epoch 22/50, Loss: 0.8939149975776672\n",
      "Epoch 23/50, Loss: 0.8824182152748108\n",
      "Epoch 24/50, Loss: 0.87044757604599\n",
      "Epoch 25/50, Loss: 0.8576117157936096\n",
      "Epoch 26/50, Loss: 0.8438774347305298\n",
      "Epoch 27/50, Loss: 0.8294322490692139\n",
      "Epoch 28/50, Loss: 0.8147320747375488\n",
      "Epoch 29/50, Loss: 0.8000884056091309\n",
      "Epoch 30/50, Loss: 0.7856118679046631\n",
      "Epoch 31/50, Loss: 0.7710060477256775\n",
      "Epoch 32/50, Loss: 0.7559667825698853\n",
      "Epoch 33/50, Loss: 0.7406051158905029\n",
      "Epoch 34/50, Loss: 0.7252193689346313\n",
      "Epoch 35/50, Loss: 0.7100350260734558\n",
      "Epoch 36/50, Loss: 0.6949822306632996\n",
      "Epoch 37/50, Loss: 0.6801465153694153\n",
      "Epoch 38/50, Loss: 0.6655917167663574\n",
      "Epoch 39/50, Loss: 0.6511057019233704\n",
      "Epoch 40/50, Loss: 0.636840283870697\n",
      "Epoch 41/50, Loss: 0.6227099895477295\n",
      "Epoch 42/50, Loss: 0.6088383793830872\n",
      "Epoch 43/50, Loss: 0.5954247117042542\n",
      "Epoch 44/50, Loss: 0.5824981927871704\n",
      "Epoch 45/50, Loss: 0.5701591968536377\n",
      "Epoch 46/50, Loss: 0.55796217918396\n",
      "Epoch 47/50, Loss: 0.5461458563804626\n",
      "Epoch 48/50, Loss: 0.5349308848381042\n",
      "Epoch 49/50, Loss: 0.5243916511535645\n",
      "Epoch 50/50, Loss: 0.5140542984008789\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Prepare input and target\n",
    "    input_data = train_data[:-1]\n",
    "    target_data = train_data[1:]\n",
    "\n",
    "    # Forward pass\n",
    "    output = model(input_data)\n",
    "    loss = loss_fn(output, target_data)\n",
    "\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.5451682806015015\n",
      "MAE: 0.5050649642944336\n",
      "MAPE: 2.413588762283325\n",
      "RMSE: 0.7383551182198858\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Prepare input and target\n",
    "    input_data = test_data[:-1]\n",
    "    target_data = test_data[1:]\n",
    "\n",
    "    # Forward pass\n",
    "    output = model(input_data)\n",
    "\n",
    "    # Calculate metrics\n",
    "    mse = mean_squared_error(target_data.numpy(), output.numpy())\n",
    "    mae = mean_absolute_error(target_data.numpy(), output.numpy())\n",
    "    mape = mean_absolute_percentage_error(target_data.numpy(), output.numpy())\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    print(f'MSE: {mse}')\n",
    "    print(f'MAE: {mae}')\n",
    "    print(f'MAPE: {mape}')\n",
    "    print(f'RMSE: {rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
