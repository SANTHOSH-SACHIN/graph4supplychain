{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error,mean_absolute_percentage_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import SAGEConv, GATConv, GeneralConv, TransformerConv\n",
    "from torch.nn import GRU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_layers, out_channels):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        prev_layer = in_channels\n",
    "\n",
    "        for hidden_dim in hidden_layers:\n",
    "            layers.append(nn.Linear(prev_layer, hidden_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            prev_layer = hidden_dim\n",
    "\n",
    "        layers.append(nn.Linear(prev_layer, out_channels))\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)\n",
    "\n",
    "\n",
    "class GRUDecoder(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, hidden_gru=64):\n",
    "        super().__init__()\n",
    "        hidden_layers = [128, 64, 32]\n",
    "\n",
    "        self.gru = nn.GRU(in_channels, hidden_gru, batch_first=True)\n",
    "        self.mlp = MLP(hidden_gru, hidden_layers, out_channels)\n",
    "\n",
    "    def forward(self, z):\n",
    "        gru_out, _ = self.gru(z)\n",
    "        output = self.mlp(gru_out.squeeze())\n",
    "        return output\n",
    "\n",
    "\n",
    "class GNNEncoder1(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv((-1, -1), hidden_channels)\n",
    "        self.conv2 = SAGEConv((-1, -1), out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index,edge_attr=None):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "class GNNEncoder2(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GATConv((-1, -1), hidden_channels, add_self_loops=False)\n",
    "        self.conv2 = GATConv((-1, -1), out_channels, add_self_loops=False)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        x = self.conv1(x, edge_index, edge_attr).relu()\n",
    "        x = self.conv2(x, edge_index, edge_attr)\n",
    "        return x\n",
    "\n",
    "class GNNEncoder3(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GeneralConv((-1, -1), hidden_channels, in_edge_channels=-1)\n",
    "        self.conv2 = GeneralConv((-1, -1), out_channels, in_edge_channels=-1)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        x = self.conv1(x, edge_index, edge_attr).relu()\n",
    "        x = self.conv2(x, edge_index, edge_attr)\n",
    "        return x\n",
    "\n",
    "class GNNEncoder4(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, heads=1, dropout=0.0, edge_dim=None):\n",
    "        super().__init__()\n",
    "        self.conv1 = TransformerConv(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=hidden_channels,\n",
    "            heads=heads,\n",
    "            concat=True,\n",
    "            beta=False,\n",
    "            dropout=dropout,\n",
    "            edge_dim=edge_dim,\n",
    "            bias=True,\n",
    "            root_weight=True\n",
    "        )\n",
    "        self.conv2 = TransformerConv(\n",
    "            in_channels=hidden_channels * heads,\n",
    "            out_channels=out_channels,\n",
    "            heads=heads,\n",
    "            concat=True,\n",
    "            beta=False,\n",
    "            dropout=dropout,\n",
    "            edge_dim=edge_dim,\n",
    "            bias=True,\n",
    "            root_weight=True\n",
    "        )\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr=None):\n",
    "        x = self.conv1(x, edge_index, edge_attr).relu()\n",
    "        x = self.conv2(x, edge_index, edge_attr)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_channels, out_channels, edge_index, edge_attr=None, encoder_type='GNNEncoder4'):\n",
    "        super().__init__()\n",
    "        if encoder_type == 'GNNEncoder1':\n",
    "            self.encoder = GNNEncoder1(hidden_channels, hidden_channels)\n",
    "        elif encoder_type == 'GNNEncoder2':\n",
    "            self.encoder = GNNEncoder2(hidden_channels, hidden_channels)\n",
    "        elif encoder_type == 'GNNEncoder3':\n",
    "            self.encoder = GNNEncoder3(hidden_channels, hidden_channels)\n",
    "        elif encoder_type == 'GNNEncoder4':\n",
    "            self.encoder = GNNEncoder4(input_size, hidden_channels, hidden_channels, edge_dim=edge_attr.size(1) if edge_attr is not None else None)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown encoder type: {encoder_type}\")\n",
    "\n",
    "        self.decoder = GRUDecoder(hidden_channels, out_channels)\n",
    "        self.edge_index = edge_index\n",
    "        self.edge_attr = edge_attr\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x, self.edge_index, self.edge_attr)\n",
    "        z = z.unsqueeze(1)\n",
    "        return self.decoder(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    speed_data = pd.read_csv('dataset/PeMSD7_V_228.csv', header=None)\n",
    "    adjacency_matrix = pd.read_csv('dataset/PeMSD7_W_228.csv', header=None)\n",
    "except FileNotFoundError:\n",
    "    import os\n",
    "    import requests\n",
    "    import zipfile\n",
    "\n",
    "    url = \"https://github.com/VeritasYin/STGCN_IJCAI-18/raw/master/dataset/PeMSD7_Full.zip\"\n",
    "    os.makedirs('dataset', exist_ok=True)\n",
    "    response = requests.get(url)\n",
    "    zip_path = 'dataset/PeMSD7_Full.zip'\n",
    "    with open(zip_path, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall('dataset')\n",
    "\n",
    "    speed_data = pd.read_csv('dataset/PeMSD7_V_228.csv', header=None)\n",
    "    adjacency_matrix = pd.read_csv('dataset/PeMSD7_W_228.csv', header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "speed_data = scaler.fit_transform(speed_data)\n",
    "\n",
    "train_size = int(len(speed_data) * 0.8)\n",
    "train_data = speed_data[:train_size]\n",
    "test_data = speed_data[train_size:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torch.tensor(train_data, dtype=torch.float32)\n",
    "test_data = torch.tensor(test_data, dtype=torch.float32)\n",
    "\n",
    "# Create edge index from adjacency matrix\n",
    "adjacency_matrix = adjacency_matrix.values  # Convert to numpy array\n",
    "edge_index = torch.tensor(np.stack(np.nonzero(adjacency_matrix)), dtype=torch.long)\n",
    "edge_attr = adjacency_matrix[edge_index[0], edge_index[1]]\n",
    "edge_attr = torch.tensor(edge_attr, dtype=torch.float).unsqueeze(1)  # Shape: [num_edges, 1]\n",
    "# Create a graph object\n",
    "graph = Data(edge_index=edge_index,edge_attr=edge_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = speed_data.shape[1]\n",
    "hidden_channels = input_size\n",
    "out_channels = speed_data.shape[1]\n",
    "num_epochs = 50\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_type = 'GNNEncoder1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(input_size, hidden_channels, out_channels, graph.edge_index, edge_attr=None, encoder_type=encoder_type)\n",
    "optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 1.005180835723877\n",
      "Epoch 2/50, Loss: 1.002534031867981\n",
      "Epoch 3/50, Loss: 1.0002368688583374\n",
      "Epoch 4/50, Loss: 0.9973888993263245\n",
      "Epoch 5/50, Loss: 0.9938968420028687\n",
      "Epoch 6/50, Loss: 0.9897443056106567\n",
      "Epoch 7/50, Loss: 0.9848119020462036\n",
      "Epoch 8/50, Loss: 0.9789284467697144\n",
      "Epoch 9/50, Loss: 0.9722875356674194\n",
      "Epoch 10/50, Loss: 0.9646264910697937\n",
      "Epoch 11/50, Loss: 0.955955445766449\n",
      "Epoch 12/50, Loss: 0.9462308287620544\n",
      "Epoch 13/50, Loss: 0.9355654716491699\n",
      "Epoch 14/50, Loss: 0.9241706728935242\n",
      "Epoch 15/50, Loss: 0.9122286438941956\n",
      "Epoch 16/50, Loss: 0.8998342752456665\n",
      "Epoch 17/50, Loss: 0.8869591951370239\n",
      "Epoch 18/50, Loss: 0.8734019994735718\n",
      "Epoch 19/50, Loss: 0.8591899871826172\n",
      "Epoch 20/50, Loss: 0.8444371223449707\n",
      "Epoch 21/50, Loss: 0.829206109046936\n",
      "Epoch 22/50, Loss: 0.8139382600784302\n",
      "Epoch 23/50, Loss: 0.7984638214111328\n",
      "Epoch 24/50, Loss: 0.7832241654396057\n",
      "Epoch 25/50, Loss: 0.7677274942398071\n",
      "Epoch 26/50, Loss: 0.7521836757659912\n",
      "Epoch 27/50, Loss: 0.7375741600990295\n",
      "Epoch 28/50, Loss: 0.7242838144302368\n",
      "Epoch 29/50, Loss: 0.7085853219032288\n",
      "Epoch 30/50, Loss: 0.6953027248382568\n",
      "Epoch 31/50, Loss: 0.6840536594390869\n",
      "Epoch 32/50, Loss: 0.6678109765052795\n",
      "Epoch 33/50, Loss: 0.6611083745956421\n",
      "Epoch 34/50, Loss: 0.643025279045105\n",
      "Epoch 35/50, Loss: 0.6351894736289978\n",
      "Epoch 36/50, Loss: 0.6202438473701477\n",
      "Epoch 37/50, Loss: 0.6086689829826355\n",
      "Epoch 38/50, Loss: 0.5986694693565369\n",
      "Epoch 39/50, Loss: 0.5853509306907654\n",
      "Epoch 40/50, Loss: 0.5757489204406738\n",
      "Epoch 41/50, Loss: 0.5653002262115479\n",
      "Epoch 42/50, Loss: 0.5547381639480591\n",
      "Epoch 43/50, Loss: 0.5455572009086609\n",
      "Epoch 44/50, Loss: 0.5353035926818848\n",
      "Epoch 45/50, Loss: 0.5263332724571228\n",
      "Epoch 46/50, Loss: 0.5169016122817993\n",
      "Epoch 47/50, Loss: 0.508682370185852\n",
      "Epoch 48/50, Loss: 0.5005366802215576\n",
      "Epoch 49/50, Loss: 0.4919903874397278\n",
      "Epoch 50/50, Loss: 0.48471230268478394\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Prepare input and target\n",
    "    input_data = train_data[:-1]\n",
    "    target_data = train_data[1:]\n",
    "\n",
    "    # Forward pass\n",
    "    output = model(input_data)\n",
    "    loss = loss_fn(output, target_data)\n",
    "\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.5069800019264221\n",
      "MAE: 0.4565073847770691\n",
      "MAPE: 2.3420441150665283\n",
      "RMSE: 0.7120252818028459\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Prepare input and target\n",
    "    input_data = test_data[:-1]\n",
    "    target_data = test_data[1:]\n",
    "\n",
    "    # Forward pass\n",
    "    output = model(input_data)\n",
    "\n",
    "    # Calculate metrics\n",
    "    mse = mean_squared_error(target_data.numpy(), output.numpy())\n",
    "    mae = mean_absolute_error(target_data.numpy(), output.numpy())\n",
    "    mape = mean_absolute_percentage_error(target_data.numpy(), output.numpy())\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    print(f'MSE: {mse}')\n",
    "    print(f'MAE: {mae}')\n",
    "    print(f'MAPE: {mape}')\n",
    "    print(f'RMSE: {rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
